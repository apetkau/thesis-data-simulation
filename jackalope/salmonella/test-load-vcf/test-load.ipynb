{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eastern-christopher",
   "metadata": {},
   "source": [
    "# Measure performance for different methods of querying variant data\n",
    "\n",
    "First let's print out the exact git commit of my thesis-index code I am using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outdoor-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41a96d85dbbb3b5910206a5fff4455dcb1cb1785\n"
     ]
    }
   ],
   "source": [
    "!git -C ../../../thesis-index rev-parse HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from storage.variant.io.SnippyVariantsReader import SnippyVariantsReader\n",
    "from pathlib import Path\n",
    "from os import listdir, path\n",
    "\n",
    "snippy_dir = Path('..', 'phylogeny')\n",
    "sample_dirs = [snippy_dir / d for d in listdir(snippy_dir) if path.isdir(snippy_dir / d)]\n",
    "\n",
    "variants_reader = SnippyVariantsReader(sample_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-oregon",
   "metadata": {},
   "source": [
    "A function used to wrap around another function and measure runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "automated-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def get_runtime(func, **args):\n",
    "    start = time.time()\n",
    "    value = func(**args)\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    return value, end - start\n",
    "\n",
    "def runtime_iteration(func, iterations = 5, print_result=True, **args):\n",
    "    runtimes = []\n",
    "    results = []\n",
    "    for i in range(0, iterations):\n",
    "        result, runtime = get_runtime(func, **args)\n",
    "        runtimes.append(runtime)\n",
    "        results.append(result)\n",
    "    \n",
    "    m_runtime = mean(runtimes)\n",
    "    s_runtime = stdev(runtimes) if len(runtimes) > 1 else 0\n",
    "    \n",
    "    if print_result:\n",
    "        print(f'Runtime (m+-s): {m_runtime:0.2f} +- {s_runtime:0.2f} seconds, iters {iterations}, result {set(results)}')\n",
    "    else:\n",
    "        print(f'Runtime (m+-s): {m_runtime:0.2f} +- {s_runtime:0.2f} seconds, iters {iterations}')\n",
    "              \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-young",
   "metadata": {},
   "source": [
    "# Test variants union\n",
    "\n",
    "Let's test getting set of all variants among a list of samples (union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lucky-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "case1_samples = ['SH12-001']\n",
    "case2_samples = [\"SH14-004\" ,\"SH13-001\" ,\"SH14-011\" ,\"SH14-016\" ,\"SH09-29\" ,\"SH12-008\" ,\"SH14-010\" ,\"SH14-028\" ,\"SH10-30\" ,\"SH12-007\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-carrier",
   "metadata": {},
   "source": [
    "## 1. From VCF files\n",
    "\n",
    "### 1.1. VCF including loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "athletic-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Runtime (m+-s): 1.31 +- 0.05 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Runtime (m+-s): 13.10 +- 0.11 seconds, iters 5, result {36920}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36920, 36920, 36920, 36920, 36920]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Set\n",
    "\n",
    "def get_union_from_vcf(samples: List[str]) -> int:\n",
    "    sample_dirs = [snippy_dir / s for s in samples]\n",
    "    variants_reader = SnippyVariantsReader(sample_dirs)\n",
    "    var_df = variants_reader.get_variants_table()\n",
    "    \n",
    "    vars_union = set()\n",
    "    var_df['SPDI'] = var_df['CHROM'] + ':' + var_df['POS'].astype(str) + ':' + var_df['REF'] + ':' + var_df['ALT']\n",
    "    for sample in samples:\n",
    "        vars_union = vars_union.union(set(var_df[var_df['SAMPLE'] == sample]['SPDI'].tolist()))\n",
    "        \n",
    "    return len(vars_union)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "runtime_iteration(get_union_from_vcf, samples=case1_samples)\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "runtime_iteration(get_union_from_vcf, samples=case2_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-illinois",
   "metadata": {},
   "source": [
    "### 1.2. VCF without loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "understanding-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Runtime (m+-s): 0.02 +- 0.00 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Runtime (m+-s): 0.35 +- 0.02 seconds, iters 5, result {36920}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{36920}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_union_from_vcf_no_load(var_df: pd.DataFrame) -> int:\n",
    "    vars_union = set()\n",
    "    samples = set(var_df['SAMPLE'].tolist())\n",
    "    var_df['SPDI'] = var_df['CHROM'] + ':' + var_df['POS'].astype(str) + ':' + var_df['REF'] + ':' + var_df['ALT']\n",
    "    for sample in samples:\n",
    "        vars_union = vars_union.union(set(var_df[var_df['SAMPLE'] == sample]['SPDI'].tolist()))\n",
    "        \n",
    "    return len(vars_union)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "\n",
    "sample_dirs = [snippy_dir / s for s in case1_samples]\n",
    "variants_reader = SnippyVariantsReader(sample_dirs)\n",
    "var_df = variants_reader.get_variants_table()\n",
    "runtime_iteration(get_union_from_vcf_no_load, var_df=var_df)\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "\n",
    "sample_dirs = [snippy_dir / s for s in case2_samples]\n",
    "variants_reader = SnippyVariantsReader(sample_dirs)\n",
    "var_df = variants_reader.get_variants_table()\n",
    "runtime_iteration(get_union_from_vcf_no_load, var_df=var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-visit",
   "metadata": {},
   "source": [
    "## 2. From relational database\n",
    "\n",
    "To test this out, I first have to load all the VCF files into the database, which takes a while. Since I'm only testing a specific query (finding union of all variants in some samples) I'm not timing this loading time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hairy-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-02-23 15:32:07\u001b[0m \u001b[1;30mINFO\u001b[0m \u001b[34mstorage.main,53:\u001b[0m Connecting to database mysql+pymysql://test:test@localhost/thesis?charset=utf8mb4\n",
      "\u001b[32m2021-02-23 15:32:07\u001b[0m \u001b[1;30mINFO\u001b[0m \u001b[34mstorage.main,56:\u001b[0m Use seqrepo directory seq_repo\n",
      "Loading ../phylogeny\n",
      "Loaded variants from [../phylogeny] into database\n",
      "Took 4.9 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "!variants --database-connection 'mysql+pymysql://test:test@localhost/thesis?charset=utf8mb4' \\\n",
    "    --seqrepo-dir seq_repo --verbose \\\n",
    "    load-snippy --reference-file ../input/S_HeidelbergSL476.fasta.gz ../phylogeny\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60:0.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "likely-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def create_session():\n",
    "    engine = create_engine('mysql+pymysql://test:test@localhost/thesis?charset=utf8mb4', echo=False)\n",
    "\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-lexington",
   "metadata": {},
   "source": [
    "### 2.1. No checking for proper reference/sequence name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "considerable-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Runtime (m+-s): 0.45 +- 0.08 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Runtime (m+-s): 3.19 +- 0.02 seconds, iters 5, result {36920}\n"
     ]
    }
   ],
   "source": [
    "from storage.variant.model import Sample\n",
    "\n",
    "def get_union_from_relational_db(samples: List[str]) -> int:\n",
    "    session = create_session()\n",
    "    sample_objs = session.query(Sample).filter(Sample.name.in_(samples)).all()\n",
    "    \n",
    "    vars_union = set()\n",
    "    for sample in sample_objs:\n",
    "        svars = {v.id for v in sample.variants}\n",
    "        vars_union = vars_union.union(svars)\n",
    "        \n",
    "    return len(vars_union)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "runtime_iteration(get_union_from_relational_db, samples=case1_samples)\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "runtime_iteration(get_union_from_relational_db, samples=case2_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-sarah",
   "metadata": {},
   "source": [
    "### 2.2. Checking for proper reference/sequence name from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deluxe-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Runtime (m+-s): 2.16 +- 0.06 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Runtime (m+-s): 3.16 +- 0.19 seconds, iters 5, result {36920}\n"
     ]
    }
   ],
   "source": [
    "from storage.variant.model import VariationAllele, ReferenceSequence, Reference\n",
    "\n",
    "def get_union_from_relational_db_via_query(samples: List[str]) -> int:\n",
    "    session = create_session()\n",
    "    variants = session.query(VariationAllele) \\\n",
    "        .select_from(Sample) \\\n",
    "        .join(Sample.variants) \\\n",
    "        .join(ReferenceSequence) \\\n",
    "        .join(Reference) \\\n",
    "        .filter(Reference.name == 'S_HeidelbergSL476') \\\n",
    "        .filter(Sample.name.in_(samples)) \\\n",
    "        .all()\n",
    "    \n",
    "    vars_union = {v.id for v in variants}\n",
    "    return len(vars_union)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "runtime_iteration(get_union_from_relational_db_via_query, samples=case1_samples)\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "runtime_iteration(get_union_from_relational_db_via_query, samples=case2_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-currency",
   "metadata": {},
   "source": [
    "### 2.3. Checking for proper reference/sequence name in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "focused-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Runtime (m+-s): 0.42 +- 0.01 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Runtime (m+-s): 3.25 +- 0.02 seconds, iters 5, result {36920}\n"
     ]
    }
   ],
   "source": [
    "from storage.variant.model import Sample, Reference, ReferenceSequence\n",
    "\n",
    "def get_union_from_relational_db_via_code(samples: List[str]) -> int:\n",
    "    session = create_session()\n",
    "    sample_objs = session.query(Sample).filter(Sample.name.in_(samples)).all()\n",
    "    ref_sequences = session.query(ReferenceSequence) \\\n",
    "        .join(Reference) \\\n",
    "        .filter(Reference.name == 'S_HeidelbergSL476') \\\n",
    "        .all()\n",
    "    \n",
    "    ref_sequence_ids = {r.id for r in ref_sequences}\n",
    "    \n",
    "    vars_union = set()\n",
    "    for sample in sample_objs:\n",
    "        svars = {v.id for v in sample.variants if v.sequence_id in ref_sequence_ids}\n",
    "        vars_union = vars_union.union(svars)\n",
    "        \n",
    "    return len(vars_union)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "runtime_iteration(get_union_from_relational_db_via_code, samples=case1_samples)\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "runtime_iteration(get_union_from_relational_db_via_code, samples=case2_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-feedback",
   "metadata": {},
   "source": [
    "## 3. From Bloom filter\n",
    "\n",
    "I am testing out Bloom filters, but I note that I don't think there's any way to extract out the specific set of variants within a Bloom filter afterwards. At least not without storing a separate mapping of variant identifiers to the specific hashes used by the Bloom filters.\n",
    "\n",
    "Nor do I think I can even get the number of elements in a Bloom filter.\n",
    "\n",
    "### 3.1. In-memory Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unlimited-updating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Building Bloom Filters\n",
      "Runtime (m+-s): 1.62 +- 0.06 seconds, iters 5\n",
      "Using Bloom Filters\n",
      "Runtime (m+-s): 0.00 +- 0.00 seconds, iters 5, result {'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)'}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Building Bloom Filters\n",
      "Runtime (m+-s): 16.16 +- 0.05 seconds, iters 5\n",
      "Using Bloom Filters\n",
      "Runtime (m+-s): 0.29 +- 0.00 seconds, iters 5, result {'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)',\n",
       " 'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)',\n",
       " 'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)',\n",
       " 'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)',\n",
       " 'BloomFilter(ideal_num_elements_n=1000000, error_rate_p=0.100000, num_bits_m=4792530)']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import copy\n",
    "\n",
    "from bloom_filter import BloomFilter\n",
    "\n",
    "def load_vcf_to_bloom_filters(samples: List[str]) -> Dict[str, BloomFilter]:\n",
    "    sample_dirs = [snippy_dir / s for s in samples]\n",
    "    variants_reader = SnippyVariantsReader(sample_dirs)\n",
    "    var_df = variants_reader.get_variants_table()\n",
    "    \n",
    "    sample_filters = {}\n",
    "    \n",
    "    vars_union = set()\n",
    "    var_df['SPDI'] = var_df['CHROM'] + ':' + var_df['POS'].astype(str) + ':' + var_df['REF'] + ':' + var_df['ALT']\n",
    "    for sample in samples:\n",
    "        sample_filters[sample] = BloomFilter(max_elements=10**6, error_rate=0.1)\n",
    "        for v in var_df[var_df['SAMPLE'] == sample]['SPDI'].tolist():\n",
    "            sample_filters[sample].add(v)\n",
    "        \n",
    "    return sample_filters\n",
    "\n",
    "def union_from_bloom_filters(sample_filters: Dict[str, BloomFilter]) -> int:\n",
    "    samples = list(sample_filters.keys())\n",
    "    sample = samples.pop()\n",
    "    start_bloom = copy.deepcopy(sample_filters[sample])\n",
    "    for sample in samples:\n",
    "        start_bloom.union(sample_filters[sample])\n",
    "        \n",
    "    return repr(start_bloom)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "print('Building Bloom Filters')\n",
    "results_case1 = runtime_iteration(load_vcf_to_bloom_filters, print_result=False, samples=case1_samples)\n",
    "print('Using Bloom Filters')\n",
    "runtime_iteration(union_from_bloom_filters, sample_filters=results_case1[0])\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "print('Building Bloom Filters')\n",
    "results_case2 = runtime_iteration(load_vcf_to_bloom_filters, print_result=False, samples=case2_samples)\n",
    "print('Using Bloom Filters')\n",
    "runtime_iteration(union_from_bloom_filters, sample_filters=results_case2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-facility",
   "metadata": {},
   "source": [
    "## 4. BCFTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fatal-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Single (1) sample\n",
      "Converting to BCF\n",
      "Runtime (m+-s): 0.41 +- 0.01 seconds, iters 5\n",
      "Finding union\n",
      "Runtime (m+-s): 0.17 +- 0.01 seconds, iters 5, result {17193}\n",
      "\n",
      "Case 2: 10 samples\n",
      "Converting to BCF\n",
      "Runtime (m+-s): 4.00 +- 0.02 seconds, iters 5\n",
      "Finding union\n",
      "Runtime (m+-s): 0.31 +- 0.01 seconds, iters 5, result {36920}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36920, 36920, 36920, 36920, 36920]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "\n",
    "def load_vcf_to_bcf(samples: List[str]) -> Dict[str, Path]:\n",
    "    bcf_dir = Path(tempfile.mkdtemp())\n",
    "    vcf_files = {s: snippy_dir / s / 'snps.vcf.gz' for s in samples}\n",
    "    bcf_files = {s: bcf_dir / f'{s}.bcf' for s in samples}\n",
    "    \n",
    "    for sample in vcf_files:\n",
    "        vcf_file = vcf_files[sample]\n",
    "        bcf_file = bcf_files[sample]\n",
    "        command_bcf = ['bcftools', 'view', str(vcf_file), '-o', str(bcf_file), '-O', 'b', '-l', '9']\n",
    "        command_index = ['bcftools', 'index', str(bcf_file)]\n",
    "        try:\n",
    "            subprocess.run(command_bcf, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                                       check=True, text=True)\n",
    "            subprocess.run(command_index, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                                       check=True, text=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            err_msg = str(e.stderr.strip())\n",
    "            raise Exception(f'Could not run bcftools on vcf_file=[{vcf_file}]: error {err_msg}')\n",
    "            \n",
    "    return bcf_files\n",
    "\n",
    "def union_from_bcf_files(sample_files: Dict[str, Path]) -> int:\n",
    "    command_isec = ['bcftools', 'isec', '-c', 'none', '-n', '+1', '--threads', '1']\n",
    "    for sample in sample_files:\n",
    "        command_isec.append(str(sample_files[sample]))\n",
    "        \n",
    "    command_single = None\n",
    "    command_single_cut = None\n",
    "    if len(sample_files) == 1:\n",
    "        sample = list(sample_files.keys())[0]\n",
    "        command_single = ['bcftools', 'view', '--threads', '1','--no-header', str(sample_files[sample])]\n",
    "        command_single_cut = ['cut', '-f', '1,2,4,5']\n",
    "        \n",
    "    try:\n",
    "        if command_single is not None:\n",
    "            result_first = subprocess.Popen(command_single, stdout=subprocess.PIPE, text=True)\n",
    "            result = subprocess.run(command_single_cut, stdin=result_first.stdout, stdout=subprocess.PIPE, text=True)\n",
    "        else:\n",
    "            result = subprocess.run(command_isec, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                                   check=True, text=True)\n",
    "        vars_data = StringIO(result.stdout)\n",
    "        var_df = pd.read_csv(vars_data, sep='\\t', names=['CHROM', 'POS', 'REF', 'ALT', 'FILES'])\n",
    "        var_df['SPDI'] = var_df['CHROM'] + ':' + var_df['POS'].astype(str) + ':' + var_df['REF'] + ':' + var_df['ALT']\n",
    "        var_set = set(var_df['SPDI'].tolist())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        err_msg = str(e.stderr.strip())\n",
    "        raise Exception(f'Could not run [{\" \".join(command)}]: error {err_msg}')\n",
    "        \n",
    "    return len(var_set)\n",
    "\n",
    "sam = [\"SH14-004\"]\n",
    "sample_bcf_files = load_vcf_to_bcf(sam)\n",
    "union_from_bcf_files(sample_bcf_files)\n",
    "\n",
    "print(f'Case 1: Single ({len(case1_samples)}) sample')\n",
    "print('Converting to BCF')\n",
    "results_case1 = runtime_iteration(load_vcf_to_bcf, print_result=False, samples=case1_samples)\n",
    "print('Finding union')\n",
    "runtime_iteration(union_from_bcf_files, sample_files=results_case1[0])\n",
    "\n",
    "print(f'\\nCase 2: {len(case2_samples)} samples')\n",
    "print('Converting to BCF')\n",
    "results_case2 = runtime_iteration(load_vcf_to_bcf, print_result=False, samples=case2_samples)\n",
    "print('Finding union')\n",
    "runtime_iteration(union_from_bcf_files, sample_files=results_case2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-catalog",
   "metadata": {},
   "source": [
    "## 5. MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-audio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
